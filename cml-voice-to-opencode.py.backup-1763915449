#!/usr/bin/env python3
"""
CML Voice-to-OpenCode with Porcupine + Whisper
===============================================
1. Listen for "C M L" wake word using Porcupine (offline)
2. Record command after wake word
3. Transcribe with local Whisper (GPU)
4. Send to OpenCode
"""

import pvporcupine
import pyaudio
import struct
import subprocess
import logging
import os
import sys
import tempfile
import time
import wave

# Setup CUDNN library path for GPU support BEFORE importing WhisperModel
cudnn_path = os.path.expanduser('~/.local/lib/python3.13/site-packages/nvidia/cudnn/lib')
cublas_path = os.path.expanduser('~/.local/lib/python3.13/site-packages/nvidia/cublas/lib')
cuda_runtime_path = os.path.expanduser('~/.local/lib/python3.13/site-packages/nvidia/cuda_runtime/lib')
if os.path.exists(cudnn_path):
    os.environ['LD_LIBRARY_PATH'] = f"{cudnn_path}:{cublas_path}:{cuda_runtime_path}:" + os.environ.get('LD_LIBRARY_PATH', '')

try:
    from faster_whisper import WhisperModel
except ImportError:
    print("ERROR: faster-whisper not installed!")
    print("Run: pip3 install faster-whisper")
    sys.exit(1)

import speech_recognition as sr

# Configuration
KEYWORD_PATH = "/home/jirka/oc/porcupine-models/C-M-L_en_linux_v3_0_0.ppn"
ACCESS_KEY = "3yFshBAX2ELWaAic9Z7qSgHfE4ZTYvXjuooTntO+4m8HoyAZFE6cMQ=="
OPENCODE_WINDOW_CLASS = "kitty"
WHISPER_MODEL_SIZE = "medium"  # medium model for better accuracy
WHISPER_LANGUAGE = "cs"  # Czech
CONFIRMATION_SOUND = os.path.expanduser("~/oc/voice-output/cache/ano-cml.mp3")

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# Initialize
recognizer = sr.Recognizer()
recognizer.pause_threshold = 2.5
mic = sr.Microphone()
whisper_model = None


def load_whisper_model():
    """Load Whisper model (lazy loading)."""
    global whisper_model
    if whisper_model is None:
        logging.info(f"üîÑ Loading Whisper model ({WHISPER_MODEL_SIZE})...")
        try:
            # Try GPU first
            whisper_model = WhisperModel(
                WHISPER_MODEL_SIZE,
                device="cuda",
                compute_type="float16"
            )
            logging.info("‚úÖ Whisper model loaded (GPU)")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è  GPU failed: {e}")
            logging.info("üîÑ Falling back to CPU...")
            whisper_model = WhisperModel(
                WHISPER_MODEL_SIZE,
                device="cpu",
                compute_type="int8"
            )
            logging.info("‚úÖ Whisper model loaded (CPU)")
    return whisper_model


def play_confirmation():
    """Play confirmation sound."""
    try:
        # Try pre-generated sound first
        if os.path.exists(CONFIRMATION_SOUND):
            subprocess.run(
                ['mpg123', '-q', CONFIRMATION_SOUND],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
        else:
            # Fallback: use TTS
            subprocess.run(
                [os.path.expanduser('~/oc/voice-output/text-to-speech.sh'), 'Ano?'],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è  Confirmation sound failed: {e}")


def show_notification(title, message):
    """Show desktop notification."""
    try:
        subprocess.run([
            'notify-send',
            '-u', 'normal',
            '-t', '2000',
            title,
            message
        ])
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è  Notification failed: {e}")


def record_command_with_pyaudio(porcupine, pa):
    """Record command using PyAudio (same stream as Porcupine)."""
    logging.info("üé§ Recording command... (speak now)")
    
    temp_file = None
    frames = []
    
    try:
        # Open stream for recording
        stream = pa.open(
            rate=16000,  # Standard rate for Whisper
            channels=1,
            format=pyaudio.paInt16,
            input=True,
            frames_per_buffer=1024
        )
        
        # Record for up to 10 seconds or until silence
        silence_threshold = 500  # Amplitude threshold
        silence_chunks = 0
        max_silence_chunks = 30  # ~2 seconds of silence at 1024 buffer
        max_chunks = 150  # ~10 seconds max
        
        for i in range(max_chunks):
            data = stream.read(1024)
            frames.append(data)
            
            # Simple silence detection
            audio_data = struct.unpack(f"{1024}h", data)
            avg_amplitude = sum(abs(x) for x in audio_data) / len(audio_data)
            
            if avg_amplitude < silence_threshold:
                silence_chunks += 1
                if silence_chunks > max_silence_chunks and i > 10:  # At least 0.5s of audio
                    logging.info("üîá Silence detected, stopping recording")
                    break
            else:
                silence_chunks = 0
        
        stream.stop_stream()
        stream.close()
        
        # Save to WAV file
        temp_file = tempfile.mktemp(suffix=".wav")
        with wave.open(temp_file, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(pa.get_sample_size(pyaudio.paInt16))
            wf.setframerate(16000)
            wf.writeframes(b''.join(frames))
        
        return temp_file
        
    except Exception as e:
        logging.error(f"‚ùå Recording error: {e}")
        if temp_file and os.path.exists(temp_file):
            os.remove(temp_file)
        return None


def transcribe_with_whisper(audio_file):
    """Transcribe audio file with Whisper."""
    try:
        logging.info("üîÑ Transcribing with Whisper...")
        
        model = load_whisper_model()
        
        # Transcribe with advanced settings (same as Caps Lock system)
        segments, info = model.transcribe(
            audio_file,
            language=WHISPER_LANGUAGE,
            beam_size=5,
            word_timestamps=True,  # Track word timing for better accuracy
            condition_on_previous_text=True,  # Use context from previous text
            vad_filter=True  # Voice Activity Detection - filter noise and silence
        )
        
        # Get text
        text = " ".join([segment.text for segment in segments]).strip()
        
        if text and len(text) >= 3:
            logging.info(f"üìù Transcribed: {text}")
            return text
        else:
            logging.warning("‚ö†Ô∏è  Transcription too short or empty")
            return None
            
    except Exception as e:
        logging.error(f"‚ùå Transcription error: {e}")
        return None


def find_kitty_socket():
    """Find the kitty socket file."""
    try:
        import glob
        sockets = glob.glob('/tmp/kitty-socket-*')
        
        if not sockets:
            logging.error("‚ùå No kitty socket found in /tmp")
            return None
        
        socket_path = sockets[0]
        logging.info(f"‚úÖ Found kitty socket: {socket_path}")
        return socket_path
        
    except Exception as e:
        logging.error(f"‚ùå Error finding kitty socket: {e}")
        return None


def send_to_opencode(text):
    """Send text to OpenCode using kitten @ and xdotool."""
    try:
        # Find kitty socket
        socket_path = find_kitty_socket()
        if not socket_path:
            return False
        
        # Read OpenCode window ID from file
        window_id_file = os.path.expanduser('~/.opencode-window-id')
        
        if not os.path.exists(window_id_file):
            logging.error("‚ùå OpenCode window ID file not found!")
            logging.error("   Run 'aic' to start OpenCode and save window ID")
            return False
        
        with open(window_id_file, 'r') as f:
            opencode_window_id = f.read().strip()
        
        if not opencode_window_id:
            logging.error("‚ùå OpenCode window ID is empty")
            return False
        
        logging.info(f"‚úÖ Using OpenCode window ID: {opencode_window_id}")
        
        # Focus the OpenCode window by ID using kitten @
        subprocess.run(
            [
                'kitten', '@',
                '--to', f'unix:{socket_path}',
                'focus-window',
                '--match', f'id:{opencode_window_id}',
            ],
            capture_output=True,
            text=True,
            check=True
        )
        
        time.sleep(0.1)
        
        # Type the text
        subprocess.run(
            ['xdotool', 'type', '--delay', '10', '--', text],
            capture_output=True,
            text=True,
            check=True
        )
        
        # Press Enter
        subprocess.run(
            ['xdotool', 'key', 'Return'],
            capture_output=True,
            text=True,
            check=True
        )
        
        logging.info(f"‚úÖ Sent to OpenCode: {text}")
        return True
        
    except subprocess.CalledProcessError as e:
        logging.error(f"‚ùå Failed to send to OpenCode: {e}")
        if e.stderr:
            logging.error(f"   stderr: {e.stderr}")
        return False
    except Exception as e:
        logging.error(f"‚ùå Error sending text: {e}")
        return False


def main():
    print("üéß CML Voice-to-OpenCode")
    print(f"üìÅ Wake word model: C M L")
    print(f"ü§ñ Whisper model: {WHISPER_MODEL_SIZE}")
    print("üé§ Listening for 'C M L'...")
    print("Press Ctrl+C to stop\n")
    
    porcupine = None
    pa = None
    audio_stream = None
    
    try:
        # Initialize Porcupine
        porcupine = pvporcupine.create(
            access_key=ACCESS_KEY,
            keyword_paths=[KEYWORD_PATH]
        )
        
        # Initialize PyAudio
        pa = pyaudio.PyAudio()
        audio_stream = pa.open(
            rate=porcupine.sample_rate,
            channels=1,
            format=pyaudio.paInt16,
            input=True,
            frames_per_buffer=porcupine.frame_length
        )
        
        logging.info("‚úÖ System ready, listening for wake word...\n")
        
        # Main loop
        while True:
            # Listen for wake word
            pcm = audio_stream.read(porcupine.frame_length)
            pcm = struct.unpack_from("h" * porcupine.frame_length, pcm)
            
            keyword_index = porcupine.process(pcm)
            
            if keyword_index >= 0:
                logging.info("üîî WAKE WORD DETECTED: C M L")
                
                # Close stream temporarily
                audio_stream.stop_stream()
                audio_stream.close()
                
                # Play confirmation
                play_confirmation()
                
                # Record command
                audio_file = record_command_with_pyaudio(porcupine, pa)
                
                if audio_file:
        # Transcribe with advanced settings (same as Caps Lock system)
        segments, info = model.transcribe(
            audio_file,
            language=WHISPER_LANGUAGE,
            beam_size=5,
            word_timestamps=True,  # Track word timing for better accuracy
            condition_on_previous_text=True,  # Use context from previous text
            vad_filter=True  # Voice Activity Detection - filter noise and silence
        )
                
                logging.info("üé§ Ready for next wake word...\n")
                
    except KeyboardInterrupt:
        print("\nüëã Stopping listener...")
    except Exception as e:
        logging.error(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if audio_stream is not None:
            try:
                audio_stream.close()
            except:
                pass
        if pa is not None:
            pa.terminate()
        if porcupine is not None:
            porcupine.delete()


if __name__ == "__main__":
    main()
